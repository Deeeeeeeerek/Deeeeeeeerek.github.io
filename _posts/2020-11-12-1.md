---

layout:     post
title:      因果推断｜统计和因果模型
subtitle:   
date:       2020-11-12
author:     Derek
header-img: img/post-sta.jpg
catalog: true
tags:
    - 因果推断
    
---

# 1. 概率论与数理统计
***

这一个系列主要是关于因果推断与学习算法的介绍，不能免俗地，我们要从定义一些符号开始. 概率论与数理统计是基于概率空间$(\Omega, \mathcal{F}, P)$的模型，其中$\Omega$是一个包含了所有可能结果的集合，$\mathcal{F}$是事件$A \subseteq \Omega$的集合，$P$是给每个事件分配一个概率的测度. 更具体的定义请见<a href="https://github.com/bayerndd/UofTNotes/blob/master/Statistics/STA347.pdf" target="_blank">概率论的笔记</a>. 概率论允许我们在给定数学结构的情况下，对随机试验的结果进行推理.

统计学习则反之，我们得到了实验的结果，从中要推断出基础数学结构的特征. 比如说我们得到了一组观测值$$(x_1, y_1), \cdots, (x_n, y_n)$$ 我们假设观测值是来自随机变量$(X_1, Y_1), \cdots, (X_n, Y_n)$的，这些随机变量是独立同分布的，且具有联合分布$P_{X, Y},$ 其中$X$和$Y$是在度量空间$\mathcal{X}$和$\mathcal{Y}$中取值的随机变量. 几乎所有的统计和机器学习问题是建立在独立同分布的数据上的，我们暂时先默认这一假设是成立的. 我们会对$P_{X, Y}$的特征感兴趣，比如说：

1. 给定输入的输出期望值，$f(x)=\mathbb{E}[Y|X=x]$——经典的回归问题（通常$\mathcal{Y}=\mathbb{R}$).
1. 将每个$x$分配给更可能的分类的二元分类器，$$f(x)=\mathop{\arg\max}_{y \in \mathcal{Y}} P(Y=y|X=x), \mathcal{Y}=\lbrace \pm1 \rbrace$$
1. $P_{X, Y}$的密度函数$p_{X, Y}.$

实践中，我们从有限的数据中估计这些特征，也即我们基于经验分布$P^n_{X, Y}$估计这些特征. 这就构成了一个逆向问题：我们要基于观测结果估计一个我们无法观测的对象属性.



# 2. 学习理论

***



现在假设我们可以从$P_{X, Y}$中获得$f,$ 我们使用经验分布来推断经验估计$f^n.$ 事实证明，这是一个难以解决的问题，因为对于任何我们在样本中没有看到的$x$值，条件期望值是未定义的. 然而，我们可以在观察到的样本上定义$f,$ 并根据任何固定的规则对其进行拓展（比如说在样本外将$f$设为$+1,$ 或者选择一个线性分段连续函数）. 但对于任何这样的选择，经验分布（输入）的微小变化都会导致输出的巨大变化. 无论我们有多少观测值，经验分布通常不会完全近似真实分布，这种近似小误差会导致估计大误差，这也就意味着，如果我们从某一类函数中选择经验估计$f^n$而不进行额外的假设，我们就不能保证估计值近似最优量$f.$ 在统计学习理论中，这些假设被正式化为容量（Capacity）——容量描述模型的拟合能力，容量低的模型不能很好的拟合训练数据，因此可能会出现欠拟合的情况，而容量大的模型可以很好的训练数据，但容易发生过拟合. 如果某一类函数容量大，可以拟合大多数可能的数据集，那么可以拟合手头的数据就不足为奇了. 但是，如果某一类函数被先验地限制为具有较小的容量，则只有少量数据可以被这一类函数解释. 如果事实证明我们仍然可以解释手中的数据，那么我们就有理由相信我们已经发现了数据的规律性. 在这种情况下，我们可以为从同一分布采样的未来数据提供解决方案准确性的概率保证.

另一种思考方式是，这一类函数结合了先验知识（Priori Knowledge），比如说函数的平滑度，并与所观察数据的规律性保持一致.

统计学习的复杂性主要在于我们需要基于观测数据解决逆向问题，如果全概率模型是给定的，那么所有的问题都迎刃而解了. 因果学习问题会更难，因为它在两个层面上是难以解决的. 除了统计上的问题（本质上是因为任意大小的有限样本将永远不会包含潜在分布的所有信息）以外，还存在着一大问题——即使完全了解观测分布，也通常无法确定潜在的因果模型.

让我们着眼于分类问题（或二进制模式识别，Binary Pattern Recognition），其中$\mathcal{Y}=\lbrace \pm1 \rbrace.$ 我们希望根据从未知的$P_{X, Y}$生成的独立同分布观测数据中学习$f: \mathcal{X} \to \mathcal{Y}.$ 我们的目标是对于某类函数$\mathcal{F}$最小化期望误差或风险$$R[f]=\int\frac{1}{2}|f(x)-y|\text{d}P_{X, Y}(x, y)$$ 如果考虑到关于Lebesgue测度的密度$p(x, y),$ 我们可以将这一积分简化为$$\int\frac{1}{2}|f(x)-y|p(x, y)\text{d}x\text{d}y$$ 因为$P_{X, Y}$是未知的，我们采用归纳原则（Induction Principle），比如将经验误差最小化——最小化对$f$的训练误差或经验风险$$R^n_\text{emp}[f]=\frac{1}{n}\sum_{i=1}^n \frac{1}{2}|f(x_i)-y_i|$$ 从渐进的（Asymptotic）观点来看，这种过程是否一致（Consistent）是非常重要的，这意味着它会产生一系列函数，当$n$趋向于无穷时，这些函数的风险在给定的函数类$\mathcal{F}$内收敛于最小的可能值. 为了证实一致性，我们需要一致大数定律：对于所有的$\varepsilon>0,$ $$\lim_{n \to \infty} P\left(\sup_{f \in \mathcal{F}}(R[f]-R^n_\text{emp}[f])>\varepsilon\right)=0$$ Vapnik-Chervonenkis（VC）维数是测量函数类容量或大小的一种可能性. VC理论表明，学习算法选择的模型的错误率是两个因素的作用结果：一是模型类越大，分类器错误率的聚集性（收敛到期望误差的速度）就越差；二是模型类越大，拟合数据效果也越好. 我们必须权衡模型的复杂度，以最小化期望误差.

这一理论与泛一致性（Universal Consistency，是指将学习算法收敛到任何函数的最低可实现误差）的现有结果并不矛盾. 尽管泛一致性告诉我们可以在无线数据的限制下学习，但它并不代表每一个问题可以从有限的数据中很好地学习.



# 3. 因果建模与学习

***

因果模型可以说是从更基本的结构开始谈起. 因果结果需要一个概率模型，但它包含后者中未包含的其它信息. 因果推理表示从因果模型的出结论的过程，类似于概率论中我们对随机试验的结果进行推理的方式. 但是由于因果模型比概率模型包含更多的信息，因果推理比概率推理更强大，它使我们能够分析干预措施或分布变化的影响.

就像统计学习是概率论的逆向问题一样，我们可以考虑如何从经验中推断因果结构. 经验可以是观察性的，但也可以包括干预措施或分布变化下的数据. 我们将因果关系结构的哪些部分可以从联合分布中推断出的紧密相关的问题称之为结构可识别性（Structure Identifiability）. 与之前描述的统计学习的问题不同（但这些问题仍然存在于因果学习的过程中），即使我们对$P$有全面的了解也不能使答案变得简单，我们需要更多的假设. 

要从观测分布中了解因果结构，我们需要了解因果模型与统计模型之间的关系（我们之后会进一步探讨）. 在此之前，我们重新提到一句众所周知的话——关联并不意味着因果，换言之，统计特征并不能确定因果关系. 鲜为人知的是，人们可能会假设——尽管我们无法推断出具体的因果结构，但我们至少可以从统计非独立性中推断出因果联系的存在——

<b>原则 1.1</b>（Reichenbach的共因原则）&nbsp;&nbsp;&nbsp; 如果随机变量$X \not\perp Y,$ 那么存在第三个变量$Z$会同时影响两者. 在特殊情况下，$Z$可以与$X$或$Y$重合. 此外，$X \perp Y|Z.$

当然，非独立性也可能由于其它原因产生，在之前的关于因果推断的完整学习中我们已经讨论过了，在此先不赘述.